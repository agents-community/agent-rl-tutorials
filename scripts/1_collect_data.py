#!/usr/bin/env python3
"""
Step 1: Data Collection with Strands + strands-vllm

This script demonstrates TITO (Token-In-Token-Out):
- Uses Strands Agent SDK for clean agent interactions
- Uses strands-vllm to capture exact token IDs
- Saves data with token IDs for RL training

Key Insight:
    With TITO, the exact tokens generated by the model are preserved.
    This prevents "retokenization drift" where:
        encode(decode(tokens)) != tokens
    
    Without TITO, RL training would update the wrong tokens!
"""

import json
import os
import re
import sys
from datetime import datetime
from typing import Any, Dict, List, Optional

# Add parent to path for config import
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from configs.config import (
    model_config, 
    training_config, 
    TRAINING_PROBLEMS, 
    format_prompt,
    SYSTEM_PROMPT,
)

from rich.console import Console
from rich.table import Table

# =============================================================================
# STRANDS + STRANDS-VLLM IMPORTS
# =============================================================================

try:
    from strands import Agent
    from strands_vllm import VLLMModel, VLLMTokenRecorder
except ImportError:
    print("‚ùå Missing dependencies. Install with:")
    print("   pip install strands-agents strands-vllm")
    sys.exit(1)

console = Console()

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def extract_answer(text: str) -> Optional[float]:
    """Extract numerical answer from response text."""
    # Try "Answer: X" format first
    match = re.search(r"Answer:\s*(-?[\d,]+\.?\d*)", text, re.IGNORECASE)
    if match:
        try:
            return float(match.group(1).replace(",", ""))
        except ValueError:
            pass
    
    # Fallback: last number in text
    numbers = re.findall(r"-?[\d,]+\.?\d*", text)
    if numbers:
        try:
            return float(numbers[-1].replace(",", ""))
        except ValueError:
            pass
    
    return None


def check_correct(predicted: Optional[float], expected: float) -> bool:
    """Check if prediction matches expected answer."""
    if predicted is None:
        return False
    tolerance = abs(expected) * 0.01 + 0.01
    return abs(predicted - expected) <= tolerance


# =============================================================================
# MAIN DATA COLLECTION
# =============================================================================

def collect_data_with_tito() -> Dict[str, Any]:
    """
    Collect training data using Strands Agent with TITO.
    
    This is the KEY FUNCTION that demonstrates:
    1. Strands Agent SDK for clean agent interactions
    2. strands-vllm's VLLMModel for token ID support
    3. VLLMTokenRecorder for capturing exact tokens
    """
    console.print("\n" + "="*60)
    console.print("üìä [bold cyan]Step 1: Data Collection with TITO[/bold cyan]")
    console.print("="*60)
    
    console.print(f"\nüì¶ Model: [green]{model_config.name}[/green]")
    console.print(f"üåê vLLM: [green]{model_config.vllm_base_url}[/green]")
    console.print(f"üìù Problems: [green]{len(TRAINING_PROBLEMS)}[/green]")
    
    # =========================================================================
    # CREATE STRANDS MODEL WITH TITO SUPPORT
    # =========================================================================
    
    console.print("\nüîß Creating Strands model with TITO...")
    
    # VLLMModel from strands-vllm - THIS IS THE KEY!
    # return_token_ids=True tells vLLM to include token IDs in responses
    strands_model = VLLMModel(
        base_url=model_config.vllm_base_url,
        model_id=model_config.name,
        return_token_ids=True,  # ‚Üê TITO: Request token IDs!
        params={"temperature": training_config.temperature},
    )
    
    console.print("   ‚úÖ VLLMModel created with [bold]return_token_ids=True[/bold]")
    
    # =========================================================================
    # COLLECT ROLLOUTS
    # =========================================================================
    
    collected_data: List[Dict[str, Any]] = []
    correct_count = 0
    tito_count = 0
    
    console.print(f"\nüéØ Collecting {len(TRAINING_PROBLEMS)} rollouts...\n")
    
    for i, problem in enumerate(TRAINING_PROBLEMS):
        question = problem["q"]
        expected = problem["a"]
        
        # Create token recorder - captures token IDs from streaming response
        # This is the TITO magic from strands-vllm!
        token_recorder = VLLMTokenRecorder()
        
        # Create Strands Agent with:
        # - VLLMModel for inference
        # - VLLMTokenRecorder as callback to capture tokens
        agent = Agent(
            model=strands_model,
            system_prompt=SYSTEM_PROMPT,
            callback_handler=token_recorder,  # ‚Üê Captures token IDs!
        )
        
        try:
            # Run the agent
            prompt = format_prompt(question)
            result = agent(prompt)
            
            # Extract response text
            if hasattr(result, 'message') and result.message:
                if hasattr(result.message, 'content') and result.message.content:
                    response_text = result.message.content[0].text if result.message.content else str(result)
                else:
                    response_text = str(result)
            else:
                response_text = str(result)
            
            # Get token IDs from recorder - THIS IS TITO!
            prompt_token_ids = token_recorder.prompt_token_ids or []
            response_token_ids = token_recorder.token_ids or []
            
            has_tito = bool(prompt_token_ids and response_token_ids)
            if has_tito:
                tito_count += 1
            
            # Calculate reward
            predicted = extract_answer(response_text)
            is_correct = check_correct(predicted, expected)
            reward = 1.0 if is_correct else 0.0
            
            if is_correct:
                correct_count += 1
                mark = "‚úì"
            else:
                mark = "‚úó"
            
            # Log progress
            tito_status = f"TITO[{len(prompt_token_ids)}/{len(response_token_ids)}]" if has_tito else "NO_TITO"
            console.print(
                f"  {mark} [{i+1:2d}/{len(TRAINING_PROBLEMS)}] "
                f"{question[:35]:35}... ‚Üí {predicted} (exp:{expected}) "
                f"[dim]{tito_status}[/dim]"
            )
            
            # Save data
            collected_data.append({
                "question": question,
                "prompt": prompt,
                "response": response_text,
                "expected_answer": expected,
                "predicted_answer": predicted,
                "reward": reward,
                "prompt_token_ids": prompt_token_ids,
                "response_token_ids": response_token_ids,
                "has_tito": has_tito,
                "timestamp": datetime.now().isoformat(),
            })
            
        except Exception as e:
            console.print(f"  ‚úó [{i+1:2d}] Error: {e}")
            collected_data.append({
                "question": question,
                "prompt": format_prompt(question),
                "response": "",
                "expected_answer": expected,
                "predicted_answer": None,
                "reward": 0.0,
                "prompt_token_ids": [],
                "response_token_ids": [],
                "has_tito": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            })
    
    # =========================================================================
    # SUMMARY
    # =========================================================================
    
    accuracy = correct_count / len(TRAINING_PROBLEMS) * 100
    tito_rate = tito_count / len(TRAINING_PROBLEMS) * 100
    
    console.print("\n" + "-"*60)
    console.print(f"üìä [bold]Results:[/bold]")
    console.print(f"   Accuracy: {correct_count}/{len(TRAINING_PROBLEMS)} ({accuracy:.1f}%)")
    console.print(f"   TITO Rate: {tito_count}/{len(TRAINING_PROBLEMS)} ({tito_rate:.1f}%)")
    
    # Show sample TITO data
    sample_with_tito = next((d for d in collected_data if d["has_tito"]), None)
    if sample_with_tito:
        console.print(f"\nüìù [bold]Sample TITO Data:[/bold]")
        console.print(f"   Question: {sample_with_tito['question'][:50]}...")
        console.print(f"   Prompt tokens: {len(sample_with_tito['prompt_token_ids'])} ‚Üí {sample_with_tito['prompt_token_ids'][:5]}...")
        console.print(f"   Response tokens: {len(sample_with_tito['response_token_ids'])} ‚Üí {sample_with_tito['response_token_ids'][:5]}...")
    
    # =========================================================================
    # SAVE DATA
    # =========================================================================
    
    output_file = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "collected_data.json"
    )
    
    output = {
        "metadata": {
            "model": model_config.name,
            "vllm_url": model_config.vllm_base_url,
            "total_samples": len(TRAINING_PROBLEMS),
            "correct_count": correct_count,
            "accuracy": accuracy,
            "tito_count": tito_count,
            "tito_rate": tito_rate,
            "timestamp": datetime.now().isoformat(),
        },
        "samples": collected_data,
    }
    
    with open(output_file, "w") as f:
        json.dump(output, f, indent=2)
    
    console.print(f"\nüíæ Data saved to: [green]{output_file}[/green]")
    console.print("="*60)
    
    return output


# =============================================================================
# MAIN
# =============================================================================

if __name__ == "__main__":
    console.print("\nüöÄ [bold]Strands + strands-vllm Data Collection[/bold]")
    console.print("   Demonstrating TITO (Token-In-Token-Out)")
    
    try:
        data = collect_data_with_tito()
        console.print("\n‚úÖ [bold green]Step 1 Complete![/bold green]")
        console.print("   Run [cyan]python scripts/2_train_rl.py[/cyan] next.")
    except Exception as e:
        console.print(f"\n‚ùå Error: {e}")
        console.print("\nMake sure vLLM is running:")
        console.print(f"   vllm serve {model_config.name} --dtype float16")

